{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Mar 27 17:10:02 2021\n",
    "\n",
    "This is NeuralLayer script file\n",
    "\n",
    "@author: taraskulyavets\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralLayer:\n",
    "    \"\"\"\n",
    "    This is Neural Layer class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights, bias, use_bipolar = False):\n",
    "        \"\"\"\n",
    "        This is Neural Layer constructor\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : numpy.ndarray\n",
    "            Layer weights.\n",
    "        bias : numpy.ndarray\n",
    "            Layer bias.\n",
    "        use_bipolar : TYPE, optional\n",
    "            A flag used to define which activation function to use. The default is False.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.use_bipolar = use_bipolar\n",
    "        self.outputs = None\n",
    "\n",
    "    def activation_function(self, u_prim):\n",
    "        \"\"\"\n",
    "        This method chooses which activation function will be used\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        u_prim : numpy.ndarray\n",
    "            List of layer outputs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Layer`s activation function output.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.use_bipolar:\n",
    "            return 2 / (1 + np.exp(-u_prim)) - 1\n",
    "        return 1 / (1 + np.exp(-u_prim))\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        \"\"\"\n",
    "        This method sends inputs through layer neurons\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : numpy.ndarray\n",
    "            Input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Layer output values\n",
    "\n",
    "        \"\"\"\n",
    "        u = np.matmul(self.weights, inputs)\n",
    "        u_prim = u + self.bias\n",
    "        y = self.activation_function(u_prim)\n",
    "        self.outputs = y\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_random_layer(input_size, layer_size, use_bipolar):\n",
    "        \"\"\"\n",
    "        This method creates new instance of Neural Layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : int\n",
    "            Size of input.\n",
    "        layer_size : int\n",
    "            Size of layer.\n",
    "        use_bipolar : bool\n",
    "            A flag used to define which activation function to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        NeuralLayer\n",
    "            New instance of Neural Layer.\n",
    "\n",
    "        \"\"\"\n",
    "        weights = np.random.rand(layer_size, input_size) * 2 - 1\n",
    "        bias = np.random.rand(layer_size) * (-1)\n",
    "        return NeuralLayer(weights, bias, use_bipolar)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    This is Neural Network class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, learning_factor = 0.1, use_bipolar = False):\n",
    "        \"\"\"\n",
    "        This is Neural Network constructor\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        layers : list\n",
    "            Neural network layers.\n",
    "        learning_factor : float, optional\n",
    "            Learning factor, define how quickly network will train. The default is 0.1.\n",
    "        use_bipolar : bool, optional\n",
    "            A flag used to define which activation function to use. The default is False.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.learning_factor = learning_factor\n",
    "        self.use_bipolar = use_bipolar\n",
    "\n",
    "    def derivative_function(self, output):\n",
    "        \"\"\"\n",
    "        This method chooses which derivative function will be used\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        output : numpy.ndarray\n",
    "            List of layer outputs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Layer`s derivative function output.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.use_bipolar:\n",
    "            return 1 - output ** 2\n",
    "        return output * (1 - output)\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        \"\"\"\n",
    "        This method sends inputs through Neural Network\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : numpy.ndarray\n",
    "            Input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Output values, which are used to predict class.\n",
    "\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.feed_forward(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def feed_backward(self, expected, row):\n",
    "        \"\"\"\n",
    "        This method changes weigths accordingly to error\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expected : list\n",
    "            List with values, which define which class we are expected.\n",
    "        row : numpy.ndarray\n",
    "            Training input.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[i]\n",
    "            if i != (len(self.layers) - 1):\n",
    "                errors =  np.matmul(self.layers[i + 1].delta, self.layers[i + 1].weights)\n",
    "            else:\n",
    "                errors = expected - layer.outputs\n",
    "            layer.delta = errors * self.derivative_function(layer.outputs)\n",
    "            if i == 0:\n",
    "                inputs = row\n",
    "            else:\n",
    "                inputs = self.layers[i - 1].outputs\n",
    "            layer.weights += np.atleast_2d(layer.delta).T * inputs * self.learning_factor\n",
    "            layer.bias += layer.delta * self.learning_factor\n",
    "\n",
    "    def train(self, train, output_classes, epochs):\n",
    "        \"\"\"\n",
    "        This method trains Neural Network and print error\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train : numpy.ndarray\n",
    "            Dataset with rows to train.\n",
    "        output_classes : list\n",
    "            List with all possible output class.\n",
    "        epochs : int\n",
    "            Number of epochs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        sum_error = 0\n",
    "        for _ in range(epochs):\n",
    "            for row in train:\n",
    "                inputs = row[:-1].astype(np.float64)\n",
    "                outputs = self.feed_forward(inputs)\n",
    "                expected = [0 for i in range(len(output_classes))]\n",
    "                expected[output_classes.index(row[-1])] = 1\n",
    "                sum_r = sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "                print(f'{row} row error - {sum_r}')\n",
    "                sum_error += sum_r\n",
    "                self.feed_backward(expected, inputs)\n",
    "        print(f'mean test error - {sum_error / (len(train) * epochs)}')\n",
    "\n",
    "    @staticmethod\n",
    "    def create_network(input_size, layers_sizes, learning_factor, use_bipolar):\n",
    "        \"\"\"\n",
    "        This method creates new instance of Neural Network\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : int\n",
    "            Size of input.\n",
    "        layers_sizes : list\n",
    "            Neural network layers sizes.\n",
    "        learning_factor : float\n",
    "            Learning factor, define how quickly network will train.\n",
    "        use_bipolar : bool\n",
    "            A flag used to define which activation function to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        NeuralNetwork\n",
    "            New instance of Neural Network.\n",
    "\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        for layer_size in layers_sizes:\n",
    "            layers.append(NeuralLayer.generate_random_layer(input_size, layer_size, use_bipolar))\n",
    "            input_size = layer_size\n",
    "        return NeuralNetwork(layers, learning_factor, use_bipolar)\n",
    "\n",
    "\n",
    "def test_network(file_name, test_split, learning_factor, hidden_size, use_bipolar, epochs):\n",
    "    \"\"\"\n",
    "    This function reads datafrom file and train neural network\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        Name of input file with dataset.\n",
    "    test_split : float\n",
    "        Percent of rows to test.\n",
    "    learning_factor : float\n",
    "        Learning factor, define how quickly network will train.\n",
    "    hidden_size : int\n",
    "        Size of hidden layer.\n",
    "    use_bipolar : bool\n",
    "        A flag used to define which activation function to use.\n",
    "    epochs : int\n",
    "        Number of epochs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    layers_sizes = [hidden_size]\n",
    "    dataset = pd.read_csv(file_name)\n",
    "    dataset = dataset.iloc[:,1:]\n",
    "    train = dataset.sample(frac = (1 - test_split))\n",
    "    test = dataset.drop(train.index)\n",
    "    train = train.to_numpy()\n",
    "    test = test.to_numpy()\n",
    "    input_size = len(train[0]) - 1\n",
    "    output_classes = list(set([row[-1] for row in np.array(dataset)]))\n",
    "    output_size = len(output_classes)\n",
    "    layers_sizes.append(output_size)\n",
    "    network = NeuralNetwork.create_network(input_size, layers_sizes, learning_factor, use_bipolar)\n",
    "    network.train(train, output_classes, epochs)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    This is main function of this module, it runs neural network testing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args : argparse.Namespace\n",
    "        Namespace containing all of argument from command line.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    test_network(args.input, args.test_split, args.learning_factor,\n",
    "                args.hidden, args.bipolar, args.epochs)\n",
    "\n",
    "\n",
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    This function parses arguments from command line\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    argparse.Namespace\n",
    "        Namespace containing all of argument from command line or their default values.\n",
    "\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=(\"Backpropagation\"))\n",
    "    parser.add_argument(\"-i\", \"--input\",\n",
    "            action=\"store\",\n",
    "            default=\"Iris.csv\",\n",
    "            help=\"Input file for training network\")\n",
    "    parser.add_argument(\"--test_split\",\n",
    "            action=\"store\",\n",
    "            type=float,\n",
    "            default=0.3,\n",
    "            help=\"What part of data should be used for validation (default 0.3)\")\n",
    "    parser.add_argument(\"-e\", \"--learning_factor\",\n",
    "            action=\"store\",\n",
    "            help=\"Learning factor\",\n",
    "            default=0.1)\n",
    "    parser.add_argument(\"--bipolar\",\n",
    "            action=\"store_true\",\n",
    "            help=\"If set use bipolar function otherwise unipolar\")\n",
    "    parser.add_argument(\"--hidden\",\n",
    "            action=\"store\",\n",
    "            type=int,\n",
    "            help=\"Size of hidden layer\",\n",
    "            default=4)\n",
    "    parser.add_argument(\"--epochs\",\n",
    "            action=\"store\",\n",
    "            type=int,\n",
    "            help=\"Number of epochs\",\n",
    "            default=100)\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(parse_arguments())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
